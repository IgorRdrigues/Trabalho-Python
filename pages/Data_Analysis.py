import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import sys
import os
from scipy import stats

# Adicionar diret√≥rio pai ao caminho para importar utils
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import calculate_basic_stats, calculate_group_stats, filter_dataframe, normalize_data

st.title("üìä An√°lise de Dados")

# Verificar se os dados foram carregados
if 'data' not in st.session_state or st.session_state.data is None:
    st.warning("Por favor, carregue seus dados primeiro usando a se√ß√£o Upload de Dados.")
    st.stop()

# Obter dados do estado da sess√£o
data = st.session_state.data
columns = st.session_state.columns
numeric_columns = st.session_state.numeric_columns
categorical_columns = st.session_state.categorical_columns

# Barra lateral para op√ß√µes de an√°lise
st.sidebar.header("Op√ß√µes de An√°lise")
analysis_type = st.sidebar.selectbox(
    "Selecione o Tipo de An√°lise",
    ["Estat√≠sticas B√°sicas", "An√°lise de Grupos", "Filtragem de Dados", "An√°lise Avan√ßada"]
)

# An√°lise de Estat√≠sticas B√°sicas
if analysis_type == "Estat√≠sticas B√°sicas":
    st.header("An√°lise Estat√≠stica B√°sica")
    
    # Selecionar coluna para an√°lise
    selected_column = st.selectbox(
        "Selecione uma coluna para an√°lise:",
        numeric_columns
    )
    
    if selected_column:
        # Calcular estat√≠sticas
        stats = calculate_basic_stats(data, selected_column)
        
        if stats:
            # Exibir estat√≠sticas em um formato agrad√°vel
            st.subheader(f"Estat√≠sticas para {selected_column}")
            
            # Criar m√∫ltiplas colunas para melhor layout
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.metric("M√©dia", round(stats['mean'], 2))
                st.metric("M√≠nimo", round(stats['min'], 2))
                st.metric("Percentil 25%", round(stats['25%'], 2))
            
            with col2:
                st.metric("Mediana", round(stats['median'], 2))
                st.metric("M√°ximo", round(stats['max'], 2))
                st.metric("Percentil 75%", round(stats['75%'], 2))
            
            with col3:
                st.metric("Desvio Padr√£o", round(stats['std'], 2))
                st.metric("Contagem", stats['count'])
                st.metric("IQR", round(stats['IQR'], 2))
            
            # Exibir histograma
            st.subheader(f"Distribui√ß√£o de {selected_column}")
            hist_values = data[selected_column].dropna()
            
            # Calcular n√∫mero de bins usando a regra de Sturges
            num_bins = int(np.ceil(np.log2(len(hist_values)) + 1))
            
            # Plotar histograma
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.hist(hist_values, bins=num_bins)
            ax.set_title(f"Histograma de {selected_column}")
            ax.set_xlabel(selected_column)
            ax.set_ylabel("Frequ√™ncia")
            st.pyplot(fig)
            
            # Exibir boxplot
            st.subheader(f"Boxplot de {selected_column}")
            fig, ax = plt.subplots(figsize=(10, 6))
            data.boxplot(column=[selected_column], ax=ax)
            st.pyplot(fig)
            
            # Identificar potenciais outliers
            q1 = stats['25%']
            q3 = stats['75%']
            iqr = stats['IQR']
            lower_bound = q1 - 1.5 * iqr
            upper_bound = q3 + 1.5 * iqr
            
            outliers = data[(data[selected_column] < lower_bound) | (data[selected_column] > upper_bound)]
            
            if not outliers.empty:
                st.subheader("Potenciais Outliers")
                st.write(f"Encontrados {len(outliers)} potenciais outliers (valores fora do intervalo [{round(lower_bound, 2)}, {round(upper_bound, 2)}])")
                st.dataframe(outliers)
        else:
            st.error("N√£o foi poss√≠vel calcular estat√≠sticas para a coluna selecionada.")

# An√°lise de Grupos
elif analysis_type == "An√°lise de Grupos":
    st.header("An√°lise de Grupos")
    
    # Selecionar colunas para agrupamento e an√°lise
    group_col = st.selectbox(
        "Selecione uma coluna para agrupar por:",
        categorical_columns
    )
    
    analysis_col = st.selectbox(
        "Selecione uma coluna num√©rica para analisar:",
        numeric_columns
    )
    
    if group_col and analysis_col:
        # Calcular estat√≠sticas de grupo
        group_stats = calculate_group_stats(data, analysis_col, group_col)
        
        if group_stats is not None:
            st.subheader(f"Estat√≠sticas de Grupo de {analysis_col} por {group_col}")
            
            # Renomear colunas para portugu√™s
            group_stats.columns = [group_col, 'Contagem', 'M√©dia', 'Mediana', 'Desvio Padr√£o', 'M√≠nimo', 'M√°ximo']
            st.dataframe(group_stats)
            
            # Plotar estat√≠sticas de grupo
            st.subheader("Compara√ß√£o de Grupos")
            
            chart_type = st.radio(
                "Selecione o tipo de gr√°fico:",
                ["Gr√°fico de Barras", "Boxplot"]
            )
            
            if chart_type == "Gr√°fico de Barras":
                # Gr√°fico de barras para valores m√©dios por grupo
                fig, ax = plt.subplots(figsize=(10, 6))
                data.groupby(group_col)[analysis_col].mean().plot(kind='bar', ax=ax)
                ax.set_title(f"M√©dia de {analysis_col} por {group_col}")
                ax.set_ylabel(analysis_col)
                st.pyplot(fig)
                
            elif chart_type == "Boxplot":
                # Boxplot para distribui√ß√£o por grupo
                fig, ax = plt.subplots(figsize=(10, 6))
                data.boxplot(column=analysis_col, by=group_col, ax=ax)
                plt.title(f"{analysis_col} por {group_col}")
                plt.suptitle("")  # Remover t√≠tulo padr√£o
                st.pyplot(fig)
            
            # Teste ANOVA se houver mais de 2 grupos (implementa√ß√£o simples)
            groups = data.groupby(group_col)[analysis_col].apply(list).values
            
            if len(groups) > 1:
                try:
                    f_val, p_val = stats.f_oneway(*groups)
                    
                    st.subheader("Teste ANOVA de uma via")
                    st.write(f"Estat√≠stica F: {f_val:.4f}")
                    st.write(f"Valor p: {p_val:.4f}")
                    
                    if p_val < 0.05:
                        st.success("H√° uma diferen√ßa estatisticamente significativa entre os grupos (p < 0,05).")
                    else:
                        st.info("N√£o h√° diferen√ßa estatisticamente significativa entre os grupos (p >= 0,05).")
                except:
                    st.warning("N√£o foi poss√≠vel realizar o teste ANOVA nos grupos selecionados.")
        else:
            st.error("N√£o foi poss√≠vel realizar an√°lise de grupo nas colunas selecionadas.")

# Filtragem de Dados
elif analysis_type == "Filtragem de Dados":
    st.header("Filtragem e Explora√ß√£o de Dados")
    
    # Criar condi√ß√µes de filtro
    st.subheader("Definir Condi√ß√µes de Filtro")
    
    filters = []
    
    # Adicionar filtros dinamicamente
    num_filters = st.number_input("N√∫mero de condi√ß√µes de filtro:", min_value=0, max_value=10, value=1)
    
    for i in range(int(num_filters)):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            filter_col = st.selectbox(f"Coluna {i+1}:", columns, key=f"filter_col_{i}")
        
        with col2:
            # Determinar operadores adequados com base no tipo de coluna
            if filter_col in numeric_columns:
                operators = ["igual a", "diferente de", "maior que", "menor que"]
            else:
                operators = ["igual a", "diferente de", "cont√©m"]
            
            filter_op = st.selectbox(f"Operador {i+1}:", operators, key=f"filter_op_{i}")
            
            # Mapear operadores em portugu√™s para ingl√™s
            op_map = {
                "igual a": "equals", 
                "diferente de": "not equals", 
                "maior que": "greater than", 
                "menor que": "less than",
                "cont√©m": "contains"
            }
        
        with col3:
            # Determinar tipo de entrada com base no tipo de coluna
            if filter_col in numeric_columns:
                filter_val = st.number_input(f"Valor {i+1}:", key=f"filter_val_{i}")
            elif filter_col in categorical_columns:
                filter_val = st.selectbox(f"Valor {i+1}:", data[filter_col].dropna().unique(), key=f"filter_val_{i}")
            else:
                filter_val = st.text_input(f"Valor {i+1}:", key=f"filter_val_{i}")
        
        filters.append((filter_col, op_map[filter_op], filter_val))
    
    # Aplicar filtros
    if st.button("Aplicar Filtros"):
        filtered_data = filter_dataframe(data, filters)
        
        st.subheader("Dados Filtrados")
        st.write(f"Mostrando {len(filtered_data)} de {len(data)} linhas ({round(len(filtered_data)/len(data)*100, 2)}%)")
        st.dataframe(filtered_data)
        
        # Baixar dados filtrados
        if not filtered_data.empty:
            csv = filtered_data.to_csv(index=False)
            st.download_button(
                "Baixar Dados Filtrados como CSV",
                csv,
                "dados_filtrados.csv",
                "text/csv",
                key='download-csv'
            )
    
    # Op√ß√µes de explora√ß√£o de dados
    st.subheader("Explora√ß√£o de Dados")
    
    # Mostrar valores √∫nicos para colunas categ√≥ricas
    if categorical_columns:
        explore_col = st.selectbox(
            "Explorar valores √∫nicos e contagens para coluna categ√≥rica:",
            categorical_columns
        )
        
        if explore_col:
            value_counts = data[explore_col].value_counts().reset_index()
            value_counts.columns = [explore_col, 'Contagem']
            
            st.write(f"Valores √∫nicos em {explore_col}:")
            st.dataframe(value_counts)
            
            # Visualizar a distribui√ß√£o
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.bar(value_counts[explore_col], value_counts['Contagem'])
            ax.set_title(f"Distribui√ß√£o de {explore_col}")
            ax.set_xlabel(explore_col)
            ax.set_ylabel("Contagem")
            plt.xticks(rotation=45)
            plt.tight_layout()
            st.pyplot(fig)

# An√°lise Avan√ßada
elif analysis_type == "An√°lise Avan√ßada":
    st.header("An√°lise Avan√ßada")
    
    advanced_option = st.selectbox(
        "Selecione o M√©todo de An√°lise Avan√ßada:",
        ["An√°lise de Correla√ß√£o", "Normaliza√ß√£o/Escala", "An√°lise de Componentes Principais (PCA)", "Clustering"]
    )
    
    # An√°lise de Correla√ß√£o
    if advanced_option == "An√°lise de Correla√ß√£o":
        st.subheader("An√°lise de Correla√ß√£o")
        
        if len(numeric_columns) < 2:
            st.warning("Necess√°rio pelo menos 2 colunas num√©ricas para an√°lise de correla√ß√£o.")
        else:
            # Selecionar colunas para correla√ß√£o
            corr_columns = st.multiselect(
                "Selecione colunas para an√°lise de correla√ß√£o:",
                numeric_columns,
                default=numeric_columns[:min(5, len(numeric_columns))]
            )
            
            if corr_columns and len(corr_columns) >= 2:
                # Calcular matriz de correla√ß√£o
                corr_matrix = data[corr_columns].corr()
                
                # Exibir matriz de correla√ß√£o
                st.write("Matriz de Correla√ß√£o:")
                st.dataframe(corr_matrix.style.background_gradient(cmap='coolwarm'))
                
                # Visualizar matriz de correla√ß√£o como mapa de calor
                fig, ax = plt.subplots(figsize=(10, 8))
                sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, ax=ax)
                st.pyplot(fig)
                
                # Encontrar e exibir pares altamente correlacionados
                high_corr_threshold = st.slider(
                    "Limiar de alta correla√ß√£o:",
                    min_value=0.5,
                    max_value=1.0,
                    value=0.7,
                    step=0.05
                )
                
                # Obter pares com alta correla√ß√£o
                corr_pairs = []
                for i in range(len(corr_matrix.columns)):
                    for j in range(i+1, len(corr_matrix.columns)):
                        if abs(corr_matrix.iloc[i, j]) >= high_corr_threshold:
                            corr_pairs.append({
                                'Vari√°vel 1': corr_matrix.columns[i],
                                'Vari√°vel 2': corr_matrix.columns[j],
                                'Correla√ß√£o': corr_matrix.iloc[i, j]
                            })
                
                if corr_pairs:
                    st.write(f"Pares altamente correlacionados (|correla√ß√£o| >= {high_corr_threshold}):")
                    st.table(pd.DataFrame(corr_pairs))
                    
                    # Gr√°fico de dispers√£o para par selecionado
                    if len(corr_pairs) > 0:
                        st.subheader("Gr√°fico de Dispers√£o para Vari√°veis Correlacionadas")
                        
                        selected_pair = st.selectbox(
                            "Selecione um par para visualizar:",
                            [f"{pair['Vari√°vel 1']} vs {pair['Vari√°vel 2']} (corr: {pair['Correla√ß√£o']:.2f})" 
                             for pair in corr_pairs]
                        )
                        
                        if selected_pair:
                            var1 = selected_pair.split(" vs ")[0]
                            var2 = selected_pair.split(" vs ")[1].split(" (corr:")[0]
                            
                            # Criar gr√°fico de dispers√£o
                            fig, ax = plt.subplots(figsize=(10, 6))
                            ax.scatter(data[var1], data[var2], alpha=0.5)
                            ax.set_xlabel(var1)
                            ax.set_ylabel(var2)
                            ax.set_title(f"Gr√°fico de Dispers√£o: {var1} vs {var2}")
                            
                            # Adicionar linha de tend√™ncia
                            slope, intercept, r_value, p_value, std_err = stats.linregress(
                                data[var1].dropna(), 
                                data[var2].dropna()
                            )
                            
                            x = np.array([data[var1].min(), data[var1].max()])
                            y = intercept + slope * x
                            ax.plot(x, y, 'r')
                            
                            st.pyplot(fig)
                else:
                    st.info(f"Nenhum par de vari√°veis com correla√ß√£o >= {high_corr_threshold} encontrado.")
    
    # Normaliza√ß√£o/Escala
    elif advanced_option == "Normaliza√ß√£o/Escala":
        st.subheader("Normaliza√ß√£o/Escala de Dados")
        
        # Selecionar colunas para normalizar
        norm_columns = st.multiselect(
            "Selecione colunas num√©ricas para normalizar:",
            numeric_columns,
            default=numeric_columns[:min(3, len(numeric_columns))]
        )
        
        if norm_columns:
            # Selecionar m√©todo de normaliza√ß√£o
            norm_method = st.radio(
                "Selecione o m√©todo de normaliza√ß√£o:",
                ["Escala Min-Max (0-1)", "Padroniza√ß√£o Z-Score", "Escala Robusta"]
            )
            
            # Mapear sele√ß√£o para nome do m√©todo
            method_map = {
                "Escala Min-Max (0-1)": "minmax",
                "Padroniza√ß√£o Z-Score": "zscore",
                "Escala Robusta": "robust"
            }
            
            # Normalizar dados
            if st.button("Aplicar Normaliza√ß√£o"):
                normalized_data = normalize_data(data, norm_columns, method_map[norm_method])
                
                # Mostrar dados originais vs normalizados
                st.write("Dados Originais vs. Normalizados (primeiras 10 linhas):")
                
                # Extrair apenas as colunas relevantes
                display_cols = norm_columns + [f"{col}_normalized" for col in norm_columns]
                st.dataframe(normalized_data[display_cols].head(10))
                
                # Visualiza√ß√£o do efeito da normaliza√ß√£o
                col1, col2 = st.columns(2)
                
                if len(norm_columns) > 0:
                    selected_col = norm_columns[0]
                    
                    with col1:
                        st.write(f"Distribui√ß√£o Original de {selected_col}")
                        fig, ax = plt.subplots()
                        ax.hist(data[selected_col].dropna(), bins=20)
                        st.pyplot(fig)
                    
                    with col2:
                        st.write(f"Distribui√ß√£o Normalizada de {selected_col}")
                        fig, ax = plt.subplots()
                        ax.hist(normalized_data[f"{selected_col}_normalized"].dropna(), bins=20)
                        st.pyplot(fig)
    
    # An√°lise de Componentes Principais (PCA)
    elif advanced_option == "An√°lise de Componentes Principais (PCA)":
        st.subheader("An√°lise de Componentes Principais (PCA)")
        
        # Verificar se h√° colunas num√©ricas suficientes
        if len(numeric_columns) < 3:
            st.warning("PCA requer pelo menos 3 colunas num√©ricas para ser √∫til. Adicione mais dados num√©ricos.")
        else:
            # Selecionar colunas para PCA
            pca_columns = st.multiselect(
                "Selecione colunas num√©ricas para PCA:",
                numeric_columns,
                default=numeric_columns[:min(5, len(numeric_columns))]
            )
            
            if pca_columns and len(pca_columns) >= 2:
                # Op√ß√µes para PCA
                n_components = st.slider(
                    "N√∫mero de componentes principais:",
                    min_value=2,
                    max_value=min(len(pca_columns), 10),
                    value=2
                )
                
                # Preparar dados para PCA
                pca_data = data[pca_columns].dropna()
                
                if len(pca_data) < 2:
                    st.error("Dados insuficientes para PCA ap√≥s remover valores ausentes.")
                else:
                    # Normalizar dados antes do PCA
                    scaler = StandardScaler()
                    scaled_data = scaler.fit_transform(pca_data)
                    
                    # Aplicar PCA
                    pca = PCA(n_components=n_components)
                    principal_components = pca.fit_transform(scaled_data)
                    
                    # Criar DataFrame com componentes principais
                    pca_df = pd.DataFrame(
                        data=principal_components,
                        columns=[f'PC{i+1}' for i in range(n_components)]
                    )
                    
                    # Exibir resultado
                    st.subheader("Componentes Principais")
                    st.dataframe(pca_df.head(10))
                    
                    # Vari√¢ncia explicada
                    explained_variance = pca.explained_variance_ratio_ * 100
                    cumulative_variance = np.cumsum(explained_variance)
                    
                    st.subheader("Vari√¢ncia Explicada")
                    
                    # Criar DataFrame de vari√¢ncia
                    variance_df = pd.DataFrame({
                        'Componente': [f'PC{i+1}' for i in range(n_components)],
                        'Vari√¢ncia Explicada (%)': explained_variance,
                        'Vari√¢ncia Acumulada (%)': cumulative_variance
                    })
                    
                    st.dataframe(variance_df)
                    
                    # Plotar vari√¢ncia explicada
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.bar(variance_df['Componente'], variance_df['Vari√¢ncia Explicada (%)'])
                    ax.set_ylabel('Vari√¢ncia Explicada (%)')
                    ax.set_title('Vari√¢ncia Explicada por Componente Principal')
                    
                    # Adicionar linha de vari√¢ncia acumulada
                    ax2 = ax.twinx()
                    ax2.plot(variance_df['Componente'], variance_df['Vari√¢ncia Acumulada (%)'], 'r-o')
                    ax2.set_ylabel('Vari√¢ncia Acumulada (%)', color='r')
                    ax2.tick_params(axis='y', labelcolor='r')
                    
                    st.pyplot(fig)
                    
                    # Visualizar proje√ß√£o nos dois primeiros componentes principais
                    if n_components >= 2:
                        st.subheader("Visualiza√ß√£o dos Dois Primeiros Componentes Principais")
                        
                        # Op√ß√£o para colorir pontos
                        if categorical_columns:
                            color_column = st.selectbox(
                                "Colorir pontos por (opcional):",
                                ["Nenhum"] + categorical_columns
                            )
                            
                            fig, ax = plt.subplots(figsize=(10, 8))
                            
                            if color_column != "Nenhum":
                                # Adicionar coluna de categoria ao DataFrame PCA
                                color_data = data[color_column].iloc[pca_data.index]
                                scatter = ax.scatter(
                                    pca_df['PC1'], 
                                    pca_df['PC2'],
                                    c=pd.factorize(color_data)[0],
                                    alpha=0.7,
                                    cmap='viridis'
                                )
                                
                                # Adicionar legenda
                                legend_handles = []
                                for i, category in enumerate(color_data.unique()):
                                    legend_handles.append(plt.Line2D([0], [0], marker='o', color='w', 
                                                       markerfacecolor=plt.cm.viridis(i / len(color_data.unique())), 
                                                       markersize=10, label=category))
                                
                                ax.legend(handles=legend_handles, title=color_column)
                            else:
                                ax.scatter(pca_df['PC1'], pca_df['PC2'], alpha=0.7)
                            
                            ax.set_xlabel('Componente Principal 1')
                            ax.set_ylabel('Componente Principal 2')
                            ax.set_title('Proje√ß√£o PCA em 2D')
                            ax.grid(True)
                            
                            st.pyplot(fig)
                        
                        # Mostrar loadings (contribui√ß√µes das vari√°veis originais)
                        st.subheader("Contribui√ß√µes das Vari√°veis Originais (Loadings)")
                        
                        loadings = pd.DataFrame(
                            pca.components_.T,
                            columns=[f'PC{i+1}' for i in range(n_components)],
                            index=pca_columns
                        )
                        
                        st.dataframe(loadings)
                        
                        # Visualizar loadings para os dois primeiros componentes
                        fig, ax = plt.subplots(figsize=(12, 8))
                        
                        # Criar mapa de calor para os loadings
                        sns.heatmap(
                            loadings.iloc[:, :2],
                            annot=True,
                            cmap='coolwarm',
                            center=0,
                            ax=ax
                        )
                        
                        ax.set_title('Contribui√ß√µes das Vari√°veis para PC1 e PC2')
                        st.pyplot(fig)
    
    # Clustering
    elif advanced_option == "Clustering":
        st.subheader("An√°lise de Clustering")
        
        # Verificar se h√° colunas num√©ricas suficientes
        if len(numeric_columns) < 2:
            st.warning("Clustering requer pelo menos 2 colunas num√©ricas.")
        else:
            # Selecionar algoritmo de clustering
            cluster_algorithm = st.selectbox(
                "Selecione o algoritmo de clustering:",
                ["K-Means"]
            )
            
            # Selecionar colunas para clustering
            cluster_columns = st.multiselect(
                "Selecione colunas num√©ricas para clustering:",
                numeric_columns,
                default=numeric_columns[:min(3, len(numeric_columns))]
            )
            
            if cluster_columns and len(cluster_columns) >= 2:
                # Preparar dados para clustering
                cluster_data = data[cluster_columns].dropna()
                
                if len(cluster_data) < 2:
                    st.error("Dados insuficientes para clustering ap√≥s remover valores ausentes.")
                else:
                    # K-Means Clustering
                    if cluster_algorithm == "K-Means":
                        # Configurar n√∫mero de clusters
                        n_clusters = st.slider("N√∫mero de clusters (k):", 2, 10, 3)
                        
                        # Normalizar dados antes do clustering
                        scaler = StandardScaler()
                        scaled_data = scaler.fit_transform(cluster_data)
                        
                        # Aplicar K-Means
                        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                        cluster_labels = kmeans.fit_predict(scaled_data)
                        
                        # Adicionar labels de cluster aos dados
                        result_df = cluster_data.copy()
                        result_df['Cluster'] = cluster_labels
                        
                        # Exibir resultados
                        st.subheader("Resultados do Clustering")
                        st.write(f"N√∫mero de clusters: {n_clusters}")
                        
                        # Contagem de amostras por cluster
                        cluster_counts = pd.DataFrame(
                            result_df['Cluster'].value_counts().sort_index()
                        ).reset_index()
                        cluster_counts.columns = ['Cluster', 'Contagem']
                        
                        st.write("Contagem de amostras por cluster:")
                        st.dataframe(cluster_counts)
                        
                        # Visualizar clusters
                        if len(cluster_columns) >= 2:
                            st.subheader("Visualiza√ß√£o de Clusters")
                            
                            if len(cluster_columns) == 2:
                                # Visualiza√ß√£o direta para 2 dimens√µes
                                x_col, y_col = cluster_columns
                                
                                fig, ax = plt.subplots(figsize=(10, 8))
                                scatter = ax.scatter(
                                    result_df[x_col],
                                    result_df[y_col],
                                    c=result_df['Cluster'],
                                    cmap='viridis',
                                    alpha=0.7
                                )
                                
                                # Adicionar centr√≥ides
                                centroids = kmeans.cluster_centers_
                                centroids_df = pd.DataFrame(
                                    scaler.inverse_transform(centroids),
                                    columns=cluster_columns
                                )
                                
                                ax.scatter(
                                    centroids_df[x_col],
                                    centroids_df[y_col],
                                    marker='X',
                                    s=200,
                                    color='red',
                                    label='Centr√≥ides'
                                )
                                
                                ax.set_xlabel(x_col)
                                ax.set_ylabel(y_col)
                                ax.set_title(f'Clusters K-Means: {x_col} vs {y_col}')
                                ax.legend()
                                
                                st.pyplot(fig)
                            else:
                                # Para mais de 2 dimens√µes, oferecer diferentes visualiza√ß√µes
                                st.write("Selecione 2 dimens√µes para visualizar:")
                                x_col = st.selectbox("Eixo X:", cluster_columns, index=0)
                                y_col = st.selectbox("Eixo Y:", cluster_columns, index=1)
                                
                                fig, ax = plt.subplots(figsize=(10, 8))
                                scatter = ax.scatter(
                                    result_df[x_col],
                                    result_df[y_col],
                                    c=result_df['Cluster'],
                                    cmap='viridis',
                                    alpha=0.7
                                )
                                
                                # Adicionar centr√≥ides (projetos nas 2 dimens√µes selecionadas)
                                centroids = kmeans.cluster_centers_
                                centroids_df = pd.DataFrame(
                                    scaler.inverse_transform(centroids),
                                    columns=cluster_columns
                                )
                                
                                ax.scatter(
                                    centroids_df[x_col],
                                    centroids_df[y_col],
                                    marker='X',
                                    s=200,
                                    color='red',
                                    label='Centr√≥ides'
                                )
                                
                                ax.set_xlabel(x_col)
                                ax.set_ylabel(y_col)
                                ax.set_title(f'Clusters K-Means: {x_col} vs {y_col}')
                                ax.legend()
                                
                                st.pyplot(fig)
                            
                            # Visualizar estat√≠sticas por cluster
                            st.subheader("Estat√≠sticas por Cluster")
                            
                            # Calcular estat√≠sticas para cada cluster
                            cluster_stats = result_df.groupby('Cluster')[cluster_columns].mean()
                            
                            # Plotar estat√≠sticas por cluster
                            fig, ax = plt.subplots(figsize=(12, 6))
                            cluster_stats.T.plot(kind='bar', ax=ax)
                            ax.set_xlabel('Atributos')
                            ax.set_ylabel('Valor M√©dio')
                            ax.set_title('Valores M√©dios dos Atributos por Cluster')
                            ax.legend(title='Cluster')
                            plt.xticks(rotation=45)
                            plt.tight_layout()
                            
                            st.pyplot(fig)
                            
                            # Radar chart para cada cluster
                            st.subheader("Perfis de Cluster (Gr√°fico Radar)")
                            
                            # Normalizar estat√≠sticas para radar chart
                            radar_stats = cluster_stats.copy()
                            for col in radar_stats.columns:
                                radar_stats[col] = (radar_stats[col] - radar_stats[col].min()) / (radar_stats[col].max() - radar_stats[col].min())
                            
                            # Plotar radar chart
                            fig = plt.figure(figsize=(12, 8))
                            
                            # Configura√ß√µes para radar chart
                            categories = cluster_columns
                            N = len(categories)
                            
                            # √Çngulos para radar chart
                            angles = [n / float(N) * 2 * np.pi for n in range(N)]
                            angles += angles[:1]  # Fechar o c√≠rculo
                            
                            # Criar subplot com proje√ß√£o polar
                            ax = plt.subplot(111, polar=True)
                            
                            # Adicionar labels
                            plt.xticks(angles[:-1], categories, size=12)
                            
                            # Adicionar linhas para cada cluster
                            for cluster in range(n_clusters):
                                values = radar_stats.iloc[cluster].values.tolist()
                                values += values[:1]  # Fechar o c√≠rculo
                                
                                ax.plot(angles, values, linewidth=2, linestyle='solid', label=f'Cluster {cluster}')
                                ax.fill(angles, values, alpha=0.1)
                            
                            plt.title('Perfis de Cluster', size=20)
                            plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))
                            
                            st.pyplot(fig)